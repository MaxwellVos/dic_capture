Index: DIC_Capture.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Author: Maxwell Vos\r\n# Date 01/2023\r\n# Capturing software used in custom DIC standalone system\r\nimport sys\r\nimport time\r\nimport serial\r\nimport csv\r\nimport cv2\r\nimport neoapi\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport math\r\nimport pyfirmata.util\r\nimport tifffile as tf\r\nfrom threading import Thread\r\nfrom pyfirmata import Arduino, util\r\nfrom time import sleep\r\nimport easygui\r\nimport os\r\n\r\n# Record mode simplifies the displays and saves all data\r\nglobal record_mode\r\nrecord_mode = False\r\n\r\nglobal exposure_time_ms\r\nexposure_time_ms = 1.6\r\n\r\nglobal camera_display\r\ncamera_display = True\r\n\r\n# Size of the array that the camera loads the images into RAM. Only first image is displayed. Used to increase fps peformance.\r\nglobal max_buffer_arr\r\nmax_buffer_arr = 3\r\n\r\nglobal test_ID\r\ntest_ID = ''\r\n\r\nif record_mode == True:\r\n    # fpsValues = [0,0.25,1,32,1,0.2,0] # pin sequence for fps, iterates array index everytime quench 4 state is changed.\r\n    # fpsValues = [0, 1, 0.125, 0.125, 0, 0.125]  # Matthew Inconel RBDT\r\n\r\n    # fpsValues = [0, 0, 0.125, 0]  # use this for calibration image capture\r\n    fpsValues = [0, 0.125, 0.125, 0.125, 0, 0.125]  # Matthew Inconel Testing\r\n\r\n    save_path = easygui.diropenbox(\r\n        default='C:/Users/maxwe/OneDrive/Documents/Masters/Test_Data/Mathew DIC',\r\n        title='Select an EMPTY folder as the save location for this test')\r\n    print(save_path)\r\n    test_ID = os.path.basename(os.path.normpath(save_path))\r\n    print(test_ID)\r\n    raw_data_save_dir = os.path.join(save_path, \"Raw_Data\")\r\n    os.mkdir(raw_data_save_dir, 0o666)\r\n    cam_1_save_dir = os.path.join(save_path, \"Camera_1\")\r\n    os.mkdir(cam_1_save_dir, 0o666)\r\n    cam_2_save_dir = os.path.join(save_path, \"Camera_2\")\r\n    os.mkdir(cam_2_save_dir, 0o666)\r\n    cam_3_save_dir = os.path.join(save_path, \"Camera_3\")\r\n    os.mkdir(cam_3_save_dir, 0o666)\r\n    synced_data_save_dir = os.path.join(save_path, \"Synced_Data\")\r\n    os.mkdir(synced_data_save_dir, 0o666)\r\n    DIC_results_save_dir = os.path.join(save_path, \"DIC_Results\")\r\n    os.mkdir(DIC_results_save_dir, 0o666)\r\nelse:\r\n    max_buffer_arr = 3\r\n    fpsValues = [0, 20, 0]\r\n    save_path = ''\r\n    test_ID = ''\r\n    raw_data_save_dir = ''\r\n    cam_1_save_dir = ''\r\n    cam_2_save_dir = ''\r\n\r\ncam1_src = 'P1-6'  # 'P1-6' USB 3 port at back of laptop, 'P1-5' is USB C to USB 3.1 adaptor\r\ncam2_src = 'P1-5'  # 'P1-6' USB 3 port at back of laptop, 'P1-5' is USB C to USB 3.1 adaptor\r\n\r\nser = serial.Serial('COM4', 115200, timeout=2)\r\n\r\n\r\ndef hardware_tigger():\r\n    # NOTE: have to wait for everything to initialize, maybe wait before calling the hardware trigger function?\r\n    sleep(1)\r\n    TCTN1_Values = ''\r\n    TCTN1_temp = ''\r\n\r\n    for i in fpsValues:\r\n        if i == 0:\r\n            TCTN1_temp = '0'\r\n        else:\r\n            TCTN1_temp = str(\r\n                round(65536 - 16000000 / (1024 * i * 2)))  # converts frame rate to arduino clock overflow start value\r\n        TCTN1_Values = TCTN1_Values + TCTN1_temp + ', '  # adds this value to a string which will be sent to the arduino\r\n    TCTN1_Values = TCTN1_Values[: -2]  # delets the ', ' from the end of the string befor sending\r\n\r\n    while True:\r\n        try:  # reads serial output from audrino\r\n            ser.write(TCTN1_Values.encode())\r\n            qValue = ser.readline().strip().decode('ascii')\r\n            print('serial output: ', qValue)\r\n            if qValue == \"RECIEVED\" and (record_mode == True):\r\n                with open(raw_data_save_dir + \"/Arduino_Serial_Output_\" + test_ID + '.txt', 'a') as f:\r\n                    heading_write_ard = 'Frame' + '\\t' + 'Time' + '\\t' + 'State' + '\\t' + 'Count' + '\\t' + 'Last_QTime' + '\\n'\r\n                    f.write(heading_write_ard)  # headings for .txt file output\r\n                break\r\n        except:\r\n            sleep(0.01)\r\n\r\n    while (record_mode == True):\r\n        try:\r\n            while (ser.inWaiting() == 0):\r\n                pass\r\n            qValue = ser.read(ser.in_waiting)\r\n\r\n            with open(raw_data_save_dir + \"/Arduino_Serial_Output_\" + test_ID + '.txt', 'a') as f:\r\n                f.write(qValue.decode('ascii'))\r\n\r\n        except:\r\n            pass\r\n\r\n\r\nclass vStream():\r\n    def __init__(self, src, windowName, timeOut_ms, buffer_arr_max, xPos, yPos, xPosHist, yPosHist, cam_save_dir):\r\n        self.buffer_arr_max = buffer_arr_max\r\n        self.timeOut_ms = timeOut_ms\r\n        self.windowName = windowName\r\n        self.zoomWindowName = windowName + ' Zoomed'\r\n        self.xPos = xPos\r\n        self.yPos = yPos\r\n        self.src = src\r\n        self.camera = neoapi.Cam()\r\n        self.camera.Connect(self.src)\r\n        self.xPosHist = xPosHist\r\n        self.yPosHist = yPosHist\r\n        self.cam_save_dir = cam_save_dir\r\n\r\n        self.camera.SetImageBufferCount(20)\r\n        self.camera.SetImageBufferCycleCount(10)\r\n\r\n        self.camera.f.PixelFormat.SetString('Mono12')\r\n        self.camera.f.ExposureTime.Set(exposure_time_ms * 1000)\r\n        self.camera.f.TriggerMode = neoapi.TriggerMode_On\r\n        # self.camera.f.TriggerSource = neoapi.TriggerSource_Software\r\n        # self.camera.f.TriggerSoftware.Execute()\r\n        self.camera.f.TriggerSource = neoapi.TriggerSource_Line2\r\n        self.camera.f.TriggerActivation = neoapi.TriggerActivation_RisingEdge\r\n        # self.camera.f.TriggerActivation neoapi.AcquisitionStatusSelector_AcquisitionTriggerWait\r\n        # self.cam_event = neoapi.NeoEvent()\r\n        # self.camera.ClearEvents()\r\n        # self.camera.EnableEvent(\"ExposureStart\")\r\n\r\n        # self.camera.EnableChunk('Image')  # enable the Image chunk to receive the data of the image\r\n        # self.camera.EnableChunk('ExposureTime')\r\n        # self.camera.EnableEvent(\"ExposureStart\")\r\n        self.triggerUpdateBool = False\r\n        self.printFPS = False\r\n        self.img_arr = []\r\n\r\n        self.thread = Thread(target=self.update, args=())\r\n        self.thread.daemon = True\r\n\r\n        self.arr_A_full = False\r\n        self.arr_B_full = False\r\n\r\n        self.thread_array_read = Thread(target=self.get_full_arr, args=())\r\n        self.thread_array_read.daemon = True\r\n\r\n        self.thread_save_array = Thread(target=self.save_array, args=())\r\n        self.thread_save_array.daemon = True\r\n\r\n        self.img_arr_A = []\r\n        self.img_arr_B = []\r\n\r\n        self.count_img = 0\r\n\r\n        self.displayWait = False\r\n\r\n        self.clicked = 0\r\n\r\n        self.scale = 0.41\r\n\r\n        self.save_last_array = False\r\n\r\n        self.cam_t0 = 0\r\n\r\n    def click_event(self, event, x, y, flags, params):\r\n        self.event = event\r\n        self.flags = flags\r\n        self.params = params\r\n        if self.event == cv2.EVENT_LBUTTONDOWN:\r\n            self.x_0 = x\r\n            self.y_0 = y\r\n            self.x_0_scaled = round(self.x_0 / self.scale)\r\n            self.y_0_scaled = round(self.y_0 / self.scale)\r\n\r\n        if self.event == cv2.EVENT_LBUTTONUP:\r\n            self.x_1 = x\r\n            self.y_1 = y\r\n            self.x_1_scaled = round(self.x_1 / self.scale)\r\n            self.y_1_scaled = round(self.y_1 / self.scale)\r\n            self.clicked = self.clicked + 1\r\n\r\n    def start_vStream(self):\r\n        self.thread.start()\r\n        self.thread_array_read.start()\r\n        self.thread_save_array.start()\r\n\r\n    def update(self):\r\n        self.temp = []\r\n        for self.k in range(0, self.buffer_arr_max):\r\n            self.img_arr_A.append(self.temp)\r\n            self.img_arr_B.append(self.temp)\r\n        while True:\r\n            for self.i in range(0, self.buffer_arr_max):\r\n                try:\r\n                    self.img = self.camera.GetImage(self.timeOut_ms)\r\n                    self.img_arr_A[self.i] = self.img\r\n                except:\r\n                    pass\r\n                    print('Image grab problem print problem')\r\n            self.arr_A_full = True\r\n            self.arr_B_full = False\r\n            for self.i in range(0, self.buffer_arr_max):\r\n                try:\r\n                    self.img = self.camera.GetImage(self.timeOut_ms)\r\n                    self.img_arr_B[self.i] = self.img\r\n                except:\r\n                    print('Image grab problem print problem')\r\n                    pass\r\n            self.arr_A_full = False\r\n            self.arr_B_full = True\r\n\r\n    def save_buffer_remainder(self):\r\n        self.save_last_array = True\r\n\r\n    def get_full_arr(self):\r\n        while True:\r\n            if self.arr_A_full:\r\n                self.arr_A_full = False\r\n                return self.img_arr_A\r\n            else:\r\n                if self.arr_B_full:\r\n                    self.arr_B_full = False\r\n                    return self.img_arr_B\r\n                else:\r\n                    return 0\r\n\r\n    def save_array(self):\r\n        if (record_mode == True):\r\n            with open(raw_data_save_dir + '/' + test_ID + '_CAM_' + self.windowName + '.txt', 'a') as f:\r\n                self.heading_cam = 'Frame' + '\\t' + 'Frame_Name' + '\\t' + 'Cam_Time' + '\\n'\r\n                f.write(self.heading_cam)\r\n        while True:\r\n            try:\r\n                self.img_arr = self.get_full_arr()\r\n                if self.save_last_array:\r\n                    if self.arr_A_full:\r\n                        self.img_arr = self.img_arr_B\r\n                    else:\r\n                        if self.arr_B_full:\r\n                            self.img_arr = self.img_arr_A\r\n                        self.save_last_array = False\r\n                if (self.img_arr != 0):\r\n                    self.frame = self.img_arr[0].GetNPArray()\r\n                    self.displayWait = False\r\n\r\n                    if (record_mode == True):\r\n                        for self.k in range(0,\r\n                                            self.buffer_arr_max):  # saves an image as .tif and adds image details to .csv file\r\n\r\n                            self.img_title = str(test_ID) + '_' + str(\r\n                                self.img_arr[self.k].GetImageID()) + '_' + self.windowName + '.tif'\r\n                            self.fileName = self.cam_save_dir + '/' + self.img_title\r\n                            self.save_img = self.img_arr[self.k].GetNPArray()\r\n                            self.img_ID = self.img_arr[self.k].GetImageID()\r\n                            self.img_TimeStamp = self.img_arr[self.k].GetTimestamp()\r\n\r\n                            if (self.img_TimeStamp != 0):\r\n                                if (self.img_ID == 0):\r\n                                    self.cam_t0 = self.img_TimeStamp\r\n                                self.img_TimeStamp_zerod = round((self.img_TimeStamp - self.cam_t0) / 1000000)\r\n                                self.data = str(self.img_ID) + '\\t' + str(self.img_title) + '\\t' + str(\r\n                                    self.img_TimeStamp_zerod) + '\\n'\r\n                                tf.imwrite(self.fileName, self.save_img, photometric='minisblack')\r\n                                with open(raw_data_save_dir + '/' + test_ID + '_CAM_' + self.windowName + '.txt',\r\n                                          'a') as f:\r\n                                    f.write(self.data)\r\n                                print('saved', self.data)\r\n\r\n\r\n            except:\r\n                print('save array error')\r\n\r\n    def displayFrame(self):\r\n        if self.displayWait == False:\r\n\r\n            self.img_8 = (self.frame / 256).astype('uint8')\r\n            self.img_heat_8 = cv2.applyColorMap(self.img_8, cv2.COLORMAP_TURBO)\r\n            # self.img_rotated = cv2.rotate(self.img_heat_8, cv2.ROTATE_90_COUNTERCLOCKWISE)\r\n            self.img_rotated = self.img_heat_8\r\n\r\n            self.width = int(self.img_rotated.shape[1] * self.scale)\r\n            self.height = int(self.img_rotated.shape[0] * self.scale)\r\n            self.dim = (self.width, self.height)\r\n\r\n            self.img_resized_8 = cv2.resize(self.img_rotated, self.dim, interpolation=cv2.INTER_AREA)\r\n\r\n            cv2.line(self.img_resized_8, (0, round(self.height / 2)), (self.width, round(self.height / 2)), (0, 255, 0),\r\n                     1)\r\n            cv2.line(self.img_resized_8, (round(self.width / 2), 0), (round(self.width / 2), self.height), (0, 255, 0),\r\n                     1)\r\n\r\n            if self.displayWait == False:\r\n                if (self.clicked > 0):\r\n                    # self.img_grey_rotated = cv2.rotate(self.img_8, cv2.ROTATE_90_COUNTERCLOCKWISE)\r\n                    self.img_grey_rotated = self.img_8\r\n                    cv2.rectangle(self.img_resized_8, (self.x_0, self.y_0), (self.x_1, self.y_1), (0, 0, 255), 2)\r\n                    self.zoomed_img = self.img_rotated[self.y_0_scaled: self.y_1_scaled,\r\n                                      self.x_0_scaled: self.x_1_scaled]\r\n                    self.zoomed_gray = self.img_grey_rotated[self.y_0_scaled: self.y_1_scaled,\r\n                                       self.x_0_scaled: self.x_1_scaled]\r\n                    cv2.imshow(self.zoomWindowName, self.zoomed_img)\r\n                    self.showHistogram()\r\n\r\n            cv2.namedWindow(self.windowName)\r\n            cv2.moveWindow(self.windowName, self.xPos, self.yPos)\r\n            cv2.imshow(self.windowName, self.img_resized_8)\r\n\r\n            self.displayWait = True\r\n\r\n    def showHistogram(self):\r\n        self.histr = cv2.calcHist([self.zoomed_gray], [0], None, [255], [0, 255])\r\n        self.histr[254] = self.histr[254] * 10000\r\n        if self.histr[254] > 0:\r\n            self.histr[254] = int(((max(self.histr) / 10)))\r\n        self.hist_height = 255\r\n        self.hist_width = 260\r\n        self.img_hist = np.zeros((self.hist_height + 1, self.hist_width), dtype=np.uint8)\r\n        for self.k in range(0, 255):\r\n            self.temp_hist = int((self.histr[self.k] / (max(self.histr))) * self.hist_height)\r\n            self.img_hist[0:self.temp_hist, self.k] = self.k  # black\r\n        self.img_hist[0:self.temp_hist, 255:self.hist_width] = self.k\r\n        self.img_hist = cv2.flip(self.img_hist, 0)\r\n        self.img_hist = (self.img_hist).astype('uint8')\r\n        self.img_hist = cv2.applyColorMap(self.img_hist, cv2.COLORMAP_TURBO)\r\n        self.hist_window_name = str(self.windowName + ' Histogram')\r\n        cv2.namedWindow(self.hist_window_name)  # Create a named window\r\n        cv2.moveWindow(self.hist_window_name, self.xPosHist, self.yPosHist)\r\n        cv2.imshow(self.hist_window_name, self.img_hist)\r\n\r\n    def getImgID(self):\r\n        return self.imgID\r\n\r\n    def getFPS(self):\r\n        return 10\r\n\r\n    def getTimestamp(self):\r\n        return self.timestamp_arr[1]\r\n\r\n    def getFrame(self):\r\n        return self.img_16\r\n\r\n    def returnCaptured(self):\r\n        return self.captured\r\n\r\n    def getFrameTimestamp(self):\r\n        return self.img_timestamp\r\n\r\n    def triggerUpdate(self):\r\n        self.triggerUpdateBool = True\r\n\r\n\r\nclass VideoShow:  # still have to work out if I still nead the video show class\r\n    \"\"\"\r\n    Class that continuously shows a frame using a dedicated thread.\r\n    \"\"\"\r\n\r\n    def __init__(self, frame=None):\r\n        self.frame = frame\r\n        self.stopped = False\r\n        self.triggerUpdateShowBool = False\r\n        self.thread = Thread(target=self.show, args=())\r\n        self.thread.daemon = True\r\n        self.thread.start()\r\n\r\n    def triggerUpdateShow(self):\r\n        self.triggerUpdateShowBool = True\r\n\r\n    def show(self):\r\n        # self.windowName = windowName\r\n        while not self.stopped:\r\n            try:\r\n                VideoShow.getScaledFrame_8(self)\r\n                cv2.imshow(self.windowName, self.img_resized_8)\r\n                if cv2.waitKey(1) == ord(\"q\"):\r\n                    self.stopped = True\r\n            except:\r\n                pass\r\n                # print('Video Show Exception')\r\n\r\n    def stop(self):\r\n        self.stopped = True\r\n\r\n    def convert16to8bit(self):\r\n        self.img_8 = (self.frame / 256).astype('uint8')\r\n\r\n    def getScaledFrame_8(self):\r\n        self.img_8 = (self.frame / 256).astype('uint8')\r\n        self.img_heat_8 = cv2.applyColorMap(self.img_8, cv2.COLORMAP_TURBO)\r\n        self.width = int((self.img_heat_8.shape[1] * 40) / 100)\r\n        self.height = int((self.img_heat_8.shape[0] * 40) / 100)\r\n        self.dim = (self.width, self.height)\r\n        self.img_resized_8 = cv2.resize(self.img_heat_8, self.dim, interpolation=cv2.INTER_AREA)\r\n\r\n\r\ndef getScaledFrame_8(img_8, scale_percent):\r\n    img_8 = cv2.applyColorMap(img_8, cv2.COLORMAP_TURBO)\r\n    width = int(img_8.shape[1] * scale_percent / 100)\r\n    height = int(img_8.shape[0] * scale_percent / 100)\r\n    dim = (width, height)\r\n    resized = cv2.resize(img_8, dim, interpolation=cv2.INTER_AREA)\r\n    return resized\r\n\r\n\r\ndef getHistogram(img_8):\r\n    histr = cv2.calcHist([img_8], [0], None, [255], [0, 255])\r\n    histr[254] = histr[254] * 500\r\n    if histr[254] > 0:\r\n        histr[254] = int(((max(histr) / 10)))\r\n    hist_height = 255\r\n    hist_width = 260\r\n    img_hist = np.zeros((hist_height + 1, hist_width), dtype=np.uint8)\r\n    for k in range(0, 255):\r\n        temp_hist = int((histr[k] / (max(histr))) * hist_height)\r\n        img_hist[0:temp_hist, k] = k  # black\r\n    img_hist[0:temp_hist, 255:hist_width] = k\r\n    img_hist = (img_hist).astype('uint8')\r\n    img_hist = cv2.applyColorMap(img_hist, cv2.COLORMAP_TURBO)\r\n\r\n    for j in range(0, 255):\r\n        temp_hist = int((histr[j] / (max(histr))) * hist_height)\r\n        img_hist[temp_hist:hist_height, j] = (255, 255, 255)\r\n        img_hist[temp_hist, j] = (0, 0, 0)\r\n\r\n    img_hist[temp_hist:hist_height, 255:hist_width] = (255, 255, 255)\r\n    img_hist[temp_hist, 255:hist_width] = (0, 0, 0)\r\n    img_hist = cv2.flip(img_hist, 0)\r\n    return img_hist\r\n\r\n\r\nif camera_display:\r\n    # displays images from the connected cameras as they are recorded\r\n    threadTrigger = Thread(target=hardware_tigger, args=())\r\n    threadTrigger.daemon = True\r\n    threadTrigger.start()\r\n\r\n    cam1 = vStream(cam1_src, '1', 4000, max_buffer_arr, -16, 0, 1655, 450, cam_1_save_dir)\r\n    cam2 = vStream(cam2_src, '2', 4000, max_buffer_arr, 823, 0, 1655, 740, cam_2_save_dir)\r\n\r\n    cam1.start_vStream()\r\n    cam2.start_vStream()\r\n\r\n    sleep(2)\r\n\r\n    while True:\r\n        try:\r\n            cam1.displayFrame()\r\n            cam2.displayFrame()\r\n            cv2.setMouseCallback(cam1.windowName, cam1.click_event)\r\n            cv2.setMouseCallback(cam2.windowName, cam2.click_event)\r\n        except:\r\n            pass\r\n        if cv2.waitKey(10) == \"TEMPORTY BLOCK\":  # ord('q'):\r\n            # save any images left in the buffer if the program is stopped\r\n            cam1.save_buffer_remainder()\r\n            cam2.save_buffer_remainder()\r\n            cv2.destroyAllWindows()\r\n            exit(1)\r\n            break\r\n\r\nelse:\r\n    # only runs the Arduino triggering system\r\n    # used when camera images are saved to an external system\r\n    threadTrigger = Thread(target=hardware_tigger, args=())\r\n    threadTrigger.daemon = True\r\n    threadTrigger.start()\r\n    while True:\r\n        if cv2.waitKey(10) == \"TEMPORTY BLOCK\":  # ord('q'):\r\n            cv2.destroyAllWindows()\r\n            exit(1)\r\n            break\r\n\r\n\"\"\"\r\nLIST OF EVENT NAMES FOR BAUMER VCXU-50:\r\nEvent name: FrameTransferSkipped\r\nEvent name: DeviceTemperatureStatusChanged\r\nEvent name: ExposureEnd\r\nEvent name: Line1RisingEdge\r\nEvent name: EventLost\r\nEvent name: TriggerOverlapped\r\nEvent name: FrameEnd\r\nEvent name: Line3RisingEdge\r\nEvent name: EventTest\r\nEvent name: ExposureStart\r\nEvent name: FrameStart\r\nEvent name: Line0FallingEdge\r\nEvent name: Line0RisingEdge\r\nEvent name: Line1FallingEdge\r\nEvent name: Line2FallingEdge\r\nEvent name: Line2RisingEdge\r\nEvent name: Line3FallingEdge\r\nEvent name: TransferBufferFull\r\nEvent name: TransferBufferReady\r\nEvent name: TriggerReady\r\nEvent name: TriggerSkipped\r\n\r\nCHUNKS:\r\n'Binning', 'BlackLevel', 'Image', 'Height', 'DeviceTemperature', 'ExposureTime', 'FrameID', 'Gain', 'Width', 'ImageControl', 'LineStatusAll', 'OffsetX', 'OffsetY', 'PixelFormat', 'Timestamp'\r\n'Binning' \r\n'BlackLevel' \r\n'Image' \r\n'Height' \r\n'DeviceTemperature' \r\n'ExposureTime' \r\n'FrameID' \r\n'Gain' \r\n'Width' \r\n'ImageControl' \r\n'LineStatusAll' \r\n'OffsetX' \r\n'OffsetY' \r\n'PixelFormat'\r\n'Timestamp'\r\n\"\"\"\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/DIC_Capture.py b/DIC_Capture.py
--- a/DIC_Capture.py	(revision 27e743f7cd53ae476a3e2b8cd3cd7c2bf9340d85)
+++ b/DIC_Capture.py	(date 1706005078860)
@@ -7,13 +7,10 @@
 import csv
 import cv2
 import neoapi
-import matplotlib.pyplot as plt
 import numpy as np
 import math
-import pyfirmata.util
 import tifffile as tf
 from threading import Thread
-from pyfirmata import Arduino, util
 from time import sleep
 import easygui
 import os
@@ -36,11 +33,11 @@
 test_ID = ''
 
 if record_mode == True:
-    # fpsValues = [0,0.25,1,32,1,0.2,0] # pin sequence for fps, iterates array index everytime quench 4 state is changed.
-    # fpsValues = [0, 1, 0.125, 0.125, 0, 0.125]  # Matthew Inconel RBDT
+    # trigger_period_ms = [0,0.25,1,32,1,0.2,0] # pin sequence for fps, iterates array index everytime quench 4 state is changed.
+    # trigger_period_ms = [0, 1, 0.125, 0.125, 0, 0.125]  # Matthew Inconel RBDT
 
-    # fpsValues = [0, 0, 0.125, 0]  # use this for calibration image capture
-    fpsValues = [0, 0.125, 0.125, 0.125, 0, 0.125]  # Matthew Inconel Testing
+    # trigger_period_ms = [0, 0, 0.125, 0]  # use this for calibration image capture
+    trigger_period_ms = [0, 4000, 4000, 4000, 0, 4000]  # Matthew Inconel Testing
 
     save_path = easygui.diropenbox(
         default='C:/Users/maxwe/OneDrive/Documents/Masters/Test_Data/Mathew DIC',
@@ -62,7 +59,7 @@
     os.mkdir(DIC_results_save_dir, 0o666)
 else:
     max_buffer_arr = 3
-    fpsValues = [0, 20, 0]
+    trigger_period_ms = [200, 0, 1000, 0, 600] #enter in ms for now
     save_path = ''
     test_ID = ''
     raw_data_save_dir = ''
@@ -72,7 +69,7 @@
 cam1_src = 'P1-6'  # 'P1-6' USB 3 port at back of laptop, 'P1-5' is USB C to USB 3.1 adaptor
 cam2_src = 'P1-5'  # 'P1-6' USB 3 port at back of laptop, 'P1-5' is USB C to USB 3.1 adaptor
 
-ser = serial.Serial('COM4', 115200, timeout=2)
+ser = serial.Serial('COM4', 250000, timeout=2)
 
 
 def hardware_tigger():
@@ -81,12 +78,11 @@
     TCTN1_Values = ''
     TCTN1_temp = ''
 
-    for i in fpsValues:
+    for i in trigger_period_ms:
         if i == 0:
             TCTN1_temp = '0'
         else:
-            TCTN1_temp = str(
-                round(65536 - 16000000 / (1024 * i * 2)))  # converts frame rate to arduino clock overflow start value
+            TCTN1_temp = str(i)  # converts frame rate to arduino clock overflow start value
         TCTN1_Values = TCTN1_Values + TCTN1_temp + ', '  # adds this value to a string which will be sent to the arduino
     TCTN1_Values = TCTN1_Values[: -2]  # delets the ', ' from the end of the string befor sending
 
